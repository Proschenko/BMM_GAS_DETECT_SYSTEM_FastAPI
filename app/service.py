import os
import cv2
import numpy as np
from ultralytics import YOLO
import subprocess
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def convert_to_mp4(input_path, output_path):
    ffmpeg_cmd = [
        "ffmpeg",
        "-y",
        "-i", input_path,
        "-c:v", "libx264",
        "-preset", "fast",
        "-crf", "23",
        "-movflags", "+faststart",
        output_path
    ]

    logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ ffmpeg: {' '.join(ffmpeg_cmd)}")
    try:
        subprocess.run(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        logger.info("‚úÖ FFmpeg: –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"[FFMPEG ERROR] –ö–æ–º–∞–Ω–¥–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {e.stderr.decode(errors='ignore')}")
        return False
    except FileNotFoundError as e:
        logger.error(f"[FFMPEG ERROR] FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Å—å, —á—Ç–æ –æ–Ω –≤ PATH: {e}")
        return False

def process_video_with_annotations(input_path, output_path):
    model_path = "models/leak_detectorv0.1.pt"

    if not os.path.exists(model_path):
        logger.error("‚ùå Model not found at %s", model_path)
        return False

    try:
        model = YOLO(model_path)
        logger.info("‚úÖ YOLO model loaded")
    except Exception as e:
        logger.exception("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ YOLO")
        return False

    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: %s", input_path)
        return False

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    logger.info(f"üìπ –í–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤, {fps:.2f} fps, —Ä–∞–∑–º–µ—Ä: {original_width}x{original_height}")

    output_size = (640, 640)
    scale_x = original_width / 640
    scale_y = original_height / 640

    tmp_path = output_path.replace(".mp4", "_raw.avi")
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(tmp_path, fourcc, fps, (original_width, original_height))

    try:
        for frame_idx in range(total_frames):
            ret, frame = cap.read()
            if not ret:
                logger.warning(f"‚ö†Ô∏è –ö–∞–¥—Ä {frame_idx} –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å")
                break

            original = frame.copy()

            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            negative = 255 - frame
            gray = cv2.cvtColor(negative, cv2.COLOR_BGR2GRAY)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            gray_eq = clahe.apply(gray)
            gray_rgb = cv2.cvtColor(gray_eq, cv2.COLOR_GRAY2RGB)
            resized = cv2.resize(gray_rgb, output_size)

            # YOLO
            results = model.predict(resized, imgsz=640, conf=0.4)
            result = results[0]
            logger.info(f"üß† –ö–∞–¥—Ä {frame_idx}: {len(result.boxes)} boxes, {len(result.masks) if result.masks else 0} masks")

            annotated = original.copy()

            if result.masks:
                for mask in result.masks.xy:
                    scaled_mask = np.array([[int(x * scale_x), int(y * scale_y)] for x, y in mask], np.int32)
                    cv2.polylines(annotated, [scaled_mask], True, (0, 255, 0), 2)
                    cv2.fillPoly(annotated, [scaled_mask], color=(0, 255, 0, 50))

            if result.boxes:
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = map(int, [x1 * scale_x, y1 * scale_y, x2 * scale_x, y2 * scale_y])
                    cls_id = int(box.cls[0].item())
                    conf = float(box.conf[0].item())
                    label = f"{model.names[cls_id]} {conf:.2f}"
                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 0, 255), 5)
                    cv2.putText(annotated, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 5)

            out.write(annotated)

    finally:
        cap.release()
        out.release()
        cv2.destroyAllWindows()

    logger.info("üíæ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∫—É –≤ MP4...")
    success = convert_to_mp4(tmp_path, output_path)

    if success:
        os.remove(tmp_path)
        logger.info("üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª—ë–Ω")
        return True
    else:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∫–µ. –§–∞–π–ª: %s", tmp_path)
        return False
